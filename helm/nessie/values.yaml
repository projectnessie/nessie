# -- The number of replicas to deploy (horizontal scaling).
# Beware that replicas are stateless; don't set this number > 1 when using IN_MEMORY or ROCKSDB version store types.
replicaCount: 1

image:
  # -- The image repository to pull from.
  repository: ghcr.io/projectnessie/nessie
  # -- The image pull policy.
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart version.
  tag: ""

# -- The default logging level for the nessie server.
logLevel: INFO

# -- Which type of version store to use: IN_MEMORY, ROCKSDB, DYNAMODB, MONGODB, CASSANDRA, JDBC, BIGTABLE.
# (Legacy version store types are: INMEMORY, ROCKS, DYNAMO, MONGO, TRANSACTIONAL. If you are using
# one of these legacy version store types, migrate your existing repositories to the new version
# store types using the nessie-server-admin-tool's export/import functionality; support for these
# legacy version store types has been removed in Nessie 0.75.0.)
versionStoreType: IN_MEMORY

# Cassandra settings. Only required when using CASSANDRA version store type; ignored otherwise.
cassandra:
  keyspace: nessie
  # -- The contact points for the Cassandra cluster. At least one contact point must be provided,
  # but more can be added for redundancy. The format is a comma-separated list of host:port elements.
  contactPoints: cassandra.cassandra.svc.cluster.local:9042
  localDatacenter: datacenter1
  secret:
    # -- The secret name to pull Cassandra credentials from.
    name: cassandra-creds
    # -- The secret key storing the Cassandra username.
    username: cassandra_username
    # -- The secret key storing the Cassandra password.
    password: cassandra_password

# RocksDB settings. Only required when using ROCKSDB version store type; ignored otherwise.
rocksdb:
  # -- The storage class name of the persistent volume claim to create.
  storageClassName: standard
  # -- The size of the persistent volume claim to create.
  storageSize: 1Gi
  # -- Labels to add to the persistent volume claim spec selector; a persistent volume with matching labels must exist.
  # Leave empty if using dynamic provisioning.
  selectorLabels:
    {}
    # app.kubernetes.io/name: nessie
    # app.kubernetes.io/instance: RELEASE-NAME

# DynamoDB settings. Only required when using DYNAMODB version store type; ignored otherwise.
dynamodb:
  # -- The AWS region to use.
  region: us-west-2
  # -- The name of the profile that should be used, when loading AWS credentials from a profile
  # file. Required only if no secret is provided below.
  profile: default
  secret:
    # -- The secret name to pull AWS credentials from. Optional; if not present, the default AWS
    # credentials provider chain is used.
    name: awscreds
    # -- The secret key storing the AWS secret key id.
    awsAccessKeyId: aws_access_key_id
    # -- The secret key storing the AWS secret access key.
    awsSecretAccessKey: aws_secret_access_key

## Mongo DB settings. Only required when using MONGODB version store type; ignored otherwise.
mongodb:
  # -- The MongoDB database name.
  name: nessie
  # -- The MongoDB connection string.
  connectionString: mongodb://localhost:27017
  secret:
    # -- The secret name to pull MongoDB credentials from.
    name: mongodb-creds
    # -- The secret key storing the MongoDB username.
    username: mongodb_username
    # -- The secret key storing the MongoDB password.
    password: mongodb_password

# JDBC datasource settings. Only required when using JDBC version store type; ignored otherwise.
jdbc:
  # -- The JDBC connection string. If you are using Nessie OSS images, then only
  # PostgreSQL, MariaDB and MySQL URLs are supported. Check your JDBC driver documentation
  # for the correct URL format.
  jdbcUrl: jdbc:postgresql://localhost:5432/my_database?currentSchema=nessie
  secret:
    # -- The secret name to pull datasource credentials from.
    name: datasource-creds
    # -- The secret key storing the datasource username.
    username: username
    # -- The secret key storing the datasource password.
    password: password

# BigTable settings. Only required when using BIGTABLE version store type; ignored otherwise.
bigtable:
  # -- The Google Cloud project ID.
  projectId: my-gcp-project
  # -- The Google Cloud Bigtable instance ID.
  instanceId: nessie-bigtable
  # -- The Google Cloud Bigtable app profile ID.
  appProfileId: default
  # -- The secret to use to authenticate against BigTable.
  # When provided, it is assumed that authentication will use a service account JSON key.
  # See https://cloud.google.com/iam/docs/keys-create-delete for details on how to create a
  # service account key.
  # If left empty, then Workload Identity usage is assumed instead; in this case, make sure that
  # the pod's service account has been granted access to BigTable.
  # See https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity#authenticating_to
  # for details on how to create a suitable service account.
  # Important: when using Workload Identity, unless the cluster is in Autopilot mode, it is also
  # required to add the following nodeSelector label:
  # iam.gke.io/gke-metadata-server-enabled: "true"
  # This is not done automatically by this chart because this selector would be invalid for
  # Autopilot clusters.
  secret: {}
    # # -- The secret name to pull a valid Google Cloud service account key from.
    # name: bigtable-creds
    # # -- The secret key storing the Google Cloud service account JSON key.
    # key: sa_json

# -- The Nessie catalog server configuration.
catalog:

  # -- Whether to enable the REST catalog service.
  enabled: false

  # -- Iceberg catalog settings.
  iceberg:

    # -- The default warehouse name. Required. This is just a symbolic name; it must refer to a
    # declared warehouse below.
    defaultWarehouse: ~  # warehouse1

    # -- Iceberg config defaults applicable to all clients and warehouses. Any properties that are
    # common to all iceberg clients should be included here. They will be passed to all clients on
    # all warehouses as config defaults. These defaults can be overridden on a per-warehouse basis,
    # see below.
    configDefaults: {}
    # io-impl: org.apache.iceberg.hadoop.HadoopFileIO

    # -- Iceberg config overrides applicable to all clients and warehouses. Any properties that are
    # common to all iceberg clients should be included here. They will be passed to all clients on
    # all warehouses as config overrides. These overrides can be overridden on a per-warehouse
    # basis, see below.
    configOverrides: {}
    # s3.acl: public-read-write

    # -- Iceberg warehouses. Each warehouse is a location where Iceberg tables are stored. Each
    # warehouse has a name, a location, and optional config defaults and overrides. At least one
    # warehouse must be defined.
    warehouses:
      # -- Symbolic name of the warehouse. Required.
    - name: ~  # warehouse1
      # -- Location of the warehouse. Required. Used to determine the base location of a table.
      # Scheme must be either s3 (Amazon S3), gs (Google GCS) or abfs / abfss (Azure ADLS). Storage
      # properties for each location can be defined below.
      location: ~  # s3://bucket1/
      # -- Iceberg config defaults specific to this warehouse. They override any defaults specified
      # above in catalog.iceberg.configDefaults.
      configDefaults: {}
      # -- Iceberg config overrides specific to this warehouse. They override any defaults specified
      # above in catalog.iceberg.configOverrides.
      configOverrides: {}
    # In rare cases it might be legit to turn off the object-stores readiness check.
    objectStoresHealthCheckEnabled: true

  # -- Catalog storage settings.
  storage:

    s3:

      # Global S3 settings. Can be overridden on a per-bucket basis below.
      defaultOptions:
        # -- DNS name of the region, required for AWS.
        region: ~  # us-west-2
        # -- Endpoint URI, required for private clouds. Optional; if not provided, the default is
        # used.
        endpoint: ~  # "https://bucket1.s3.amazonaws.com"
        # -- Endpoint URI, required for private clouds. Optional; if not provided, the default is
        # used. If the endpoint URIs for the Nessie server and clients differ, this one defines the
        # endpoint used for the Nessie server.
        externalEndpoint: ~
        # -- Whether to use path-style access. Optional; if not provided, the default is used. If
        # true, path-style access will be used, as in: https://<domain>/<bucket>. If false, a
        # virtual-hosted style will be used instead, as in: https://<bucket>.<domain>.
        pathStyleAccess: false
        # -- AWS Access point for this bucket. Access points can be used to perform S3 operations by
        # specifying a mapping of bucket to access points. This is useful for multi-region access,
        # cross-region access, disaster recovery, etc. See
        # https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-access-points.html.
        accessPoint: ~
        # -- Authorize cross-region calls when contacting an access point. The default is false.
        allowCrossRegionAccessPoint: false
        # -- Controls the authentication mode for the Catalog server. Valid values are:
        # - APPLICATION_GLOBAL: Use the default AWS credentials provider chain.
        # - STATIC: Static credentials provided through the accessKeySecret option.
        # The default is STATIC.
        serverAuthenticationMode: ~  # STATIC
        # -- Controls the authentication mode for Catalog clients accessing this bucket. Valid values
        # are:
        # - REQUEST_SIGNING: Each client I/O request is individually authorized (signed) by the
        # Catalog server. This is the default.
        # - ASSUME_ROLE: Clients receive session credentials (according to the role and IAM policy
        # from bucket configuration) for the whole duration of client sessions.
        clientAuthenticationMode: ~  # REQUEST_SIGNING

        # -- Settings only relevant when clientAuthenticationMode is ASSUME_ROLE.
        assumeRole:
          # -- The STS endpoint. Optional; if not provided, the default is used. This parameter must
          # be set if the cloud provider is not AMAZON and the catalog is configured to use S3
          # sessions (e.g. to use the "assume role" functionality).
          stsEndpoint: ~  # "https://sts.amazonaws.com"
          # -- The ARN of the role to assume for accessing S3 data. This parameter is required for
          # Amazon S3, but may not be required for other storage providers (e.g. Minio does not use it
          # at all).
          roleArn: ~  # "arn:aws:iam::123456789012:role/role-name"
          # -- The IAM policy in JSON format to be used as an inline session policy. Optional.
          sessionIamPolicy: ~  # "{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"s3:*\", \"Resource\": \"*\" } ] }"
          # -- An identifier for the assumed role session. This parameter is most important in cases
          # when the same role is assumed by different principals in different use cases.
          roleSessionName: ~  # nessie
          # -- An identifier for the party assuming the role. This parameter must match the external
          # ID configured in IAM rules that govern the assume role process for the specified roleArn.
          externalId: ~
          # -- A higher bound estimate of the expected duration of client "sessions" working with data in
          # this bucket. A session, for example, is the lifetime of an Iceberg REST catalog object on
          # the client side. This value is used for validating expiration times of credentials
          # associated with the warehouse. If unset, a default of one hour is assumed.
          clientSessionDuration: ~

        # -- AWS credentials. Required when serverAuthenticationMode is STATIC.
        accessKeySecret:
          # -- The secret name to pull AWS credentials from.
          name: ~
          # -- The secret key storing the AWS secret key id.
          awsAccessKeyId: ~
          # -- The secret key storing the AWS secret access key.
          awsSecretAccessKey: ~

      # -- Per-bucket S3 settings. Override the general settings above.
      buckets: []
      # - name: bucket1
      #   endpoint: "https://bucket1.s3.amazonaws.com"
      #   accessKeySecret:
      #     name: awscreds
      #     awsAccessKeyId: aws_access_key_id
      #     awsSecretAccessKey: aws_secret_access_key

      # -- S3 transport settings. Not overridable on a per-bucket basis.
      transport:
        # -- Override the default maximum number of pooled connections.
        maxHttpConnections: ~
        # -- Override the default connection read timeout. Must be a valid ISO duration.
        readTimeout: ~
        # -- Override the default TCP connect timeout. Must be a valid ISO duration.
        connectTimeout: ~
        # -- Override default connection acquisition timeout. This is the time a request will wait
        # for a connection from the pool. Must be a valid ISO duration.
        connectionAcquisitionTimeout: ~
        # -- Override default max idle time of a pooled connection. Must be a valid ISO duration.
        connectionMaxIdleTime: ~
        # -- Override default time-time of a pooled connection. Must be a valid ISO duration.
        connectionTimeToLive: ~
        # -- Override default behavior whether to expect an HTTP/100-Continue. Must be a valid ISO
        # duration.
        expectContinueEnabled: ~
        # -- Interval after which a request is retried when S3 response with some "retry later"
        # response. Must be a valid ISO duration.
        retryAfter: ~

      sessionCredentials:
        # -- The time period to subtract from the S3 session credentials (assumed role credentials)
        # expiry time to define the time when those credentials become eligible for refreshing.
        # Not overridable on a per-bucket basis. The default is PT5M (5 minutes).
        sessionCredentialRefreshGracePeriod: ~  # PT5M
        # -- Maximum number of entries to keep in the session credentials cache (assumed role
        # credentials). Not overridable on a per-bucket basis. The default is 1000.
        sessionCredentialCacheMaxEntries: ~  # 1000
        # -- Maximum number of entries to keep in the STS clients cache. Not overridable on a
        # per-bucket basis. The default is 50.
        stsClientsCacheMaxEntries: ~  # 50

    gcs:

      # Global GCS settings. Can be overridden on a per-bucket basis below.
      defaultOptions:
        # -- The default endpoint override to use. The endpoint is almost always used for testing
        # purposes. If the endpoint URIs for the Nessie server and clients differ, this one defines
        # the endpoint used for the Nessie server.
        host: ~
        # -- When using a specific endpoint, see host, and the endpoint URIs for the Nessie server
        # differ, you can specify the URI passed down to clients using this setting. Otherwise,
        # clients will receive the value from the host setting.
        externalHost: ~
        # -- Optionally specify the user project (Google term).
        userProject: ~
        # --  The Google project ID.
        projectId: ~
        # -- The Google quota project ID.
        quotaProjectId: ~
        # -- The Google client lib token.
        clientLibToken: ~
        # -- The authentication type to use. Valid values are: NONE, USER, SERVICE_ACCOUNT,
        # ACCESS_TOKEN. The default is NONE.
        authType: ~

        # -- The Google Cloud service account key secret. This is required when authType is USER or
        # SERVICE_ACCOUNT.
        authCredentialsJsonSecret:
          # -- The secret name to pull a valid Google Cloud service account key from.
          name: ~
          # -- The secret key storing the Google Cloud service account JSON key.
          key: ~

        # -- The oauth2 token secret. This is required when authType is ACCESS_TOKEN.
        oauth2TokenSecret:
          # # -- The secret name to pull a valid Google Cloud service account key from.
          name: ~
          # # -- The secret key storing the token.
          token: ~
          # # -- The secret key storing the token's expiresAt value (optional).
          expiresAt: ~

        # -- Customer-supplied AES256 key for blob encryption when writing. Currently unsupported.
        encryptionKey: ~
        # -- Customer-supplied AES256 key for blob decryption when reading. Currently unsupported.
        decryptionKey: ~

        # -- The read chunk size in bytes. Must be a valid ISO duration.
        readChunkSize: ~
        # -- The write chunk size in bytes. Must be a valid ISO duration.
        writeChunkSize: ~
        # -- The delete batch size.
        deleteBatchSize: ~

      # -- Per-bucket GCS settings. Override the general settings above.
      buckets: []
      # - name: bucket1
      #   authType: ACCESS_TOKEN
      #   oauth2TokenSecret:
      #     - name: gcs-creds
      #       key: token
      #       expiresAt: expiresAt

      # -- GCS transport settings. Not overridable on a per-bucket basis.
      transport:
        # -- Override the default maximum number of attempts.
        maxAttempts: ~
        # -- Override the default connection timeout. Must be a valid ISO duration.
        connectTimeout: ~
        # -- Override the default read timeout. Must be a valid ISO duration.
        readTimeout: ~
        # -- Override the default initial retry delay. Must be a valid ISO duration.
        initialRetryDelay: ~
        # -- Override the default maximum retry delay. Must be a valid ISO duration.
        maxRetryDelay: ~
        # -- Override the default retry delay multiplier. Must be a valid ISO duration.
        retryDelayMultiplier: ~
        # -- Override the default initial RPC timeout. Must be a valid ISO duration.
        initialRpcTimeout: ~
        # -- Override the default maximum RPC timeout. Must be a valid ISO duration.
        maxRpcTimeout: ~
        # -- Override the default RPC timeout multiplier. Must be a valid ISO duration.
        rpcTimeoutMultiplier: ~
        # -- Override the default logical request timeout. Must be a valid ISO duration.
        logicalTimeout: ~
        # -- Override the default total timeout. Must be a valid ISO duration.
        totalTimeout: ~

    adls:

      # Global ADLS settings. Can be overridden on a per-filesystem basis below.
      defaultOptions:
        # -- A secret containing the account name and key to use. Either this option or sasTokenSecret
        # must be set. If both are set, sasTokenSecret takes precedence.
        accountSecret:
          # -- Name of the secret containing the account name and key.
          name: ~
          # -- Secret key containing the fully-qualified account name, e.g. "myaccount.dfs.core.windows.net".
          accountName: ~
          # -- Secret key containing the account key.
          accountKey: ~

        # -- A secret containing the SAS token to use. Either this option or accountSecret must
        # be set. If both are set, sasTokenSecret takes precedence.
        sasTokenSecret:
          # -- Name of the secret containing the SAS token.
          name: ~
          # -- Secret key containing the SAS token.
          sasToken: ~

        # -- Custom HTTP endpoint. In case clients need to use a different URI, use externalEndpoint.
        endpoint: ~

        # -- Custom HTTP endpoint to be used by clients. If not set, the endpoint value is used.
        externalEndpoint: ~

      # -- Per-filesystem ADLS settings. Override the general settings above.
      filesystems: []
      # - name: filesystem1
      #   endpoint: http://localhost/adlsgen2/bucket
      #   accountSecret:
      #     name: adls-account-secret
      #     accountName: accountName
      #     accountKey: accountKeyRef

      # -- ADLS transport settings. Not overridable on a per-bucket basis.
      transport:
        # -- The retry strategy to use. Valid values are: NONE, EXPONENTIAL_BACKOFF, FIXED_DELAY.
        # The default is EXPONENTIAL_BACKOFF.
        retryPolicy: ~
        # -- The maximum number of retries. Must be a positive integer. Default is 4. Optional.
        # Valid if retryPolicy is EXPONENTIAL_BACKOFF or FIXED_DELAY.
        maxRetries: ~
        # -- The maximum time allowed before a request is cancelled and assumed failed, default is
        # Integer.MAX_VALUE. Optional. Must be a valid ISO duration. Valid if retryPolicy is
        # EXPONENTIAL_BACKOFF or FIXED_DELAY.
        tryTimeout: ~
        # -- Specifies the amount of delay to use before retrying an operation, default value is
        # PT4S (4 seconds) when retryPolicy is EXPONENTIAL_BACKOFF and PT30S (30 seconds) when
        # retryPolicy is FIXED_DELAY. Must be a valid ISO duration.
        retryDelay: ~
        # --  Specifies the maximum delay allowed before retrying an operation, default value is
        # PT120s (120 seconds). Must be a valid ISO duration. Valid if retryPolicy is
        # EXPONENTIAL_BACKOFF.
        maxRetryDelay: ~
        # -- The default maximum connection pool size is determined by the underlying HTTP client.
        # Not overridable on a per-filesystem basis.
        maxHttpConnections: ~
        # -- Sets the connection timeout for a request to be sent. The default is PT10S (10
        # seconds). Must be a valid ISO duration. Not overridable on a per-filesystem basis.
        connectTimeout: ~
        # -- Sets the read timeout duration used when reading the server response. The default is
        # PT60S (60 seconds). Must be a valid ISO duration. Not overridable on a per-filesystem
        # basis.
        readTimeout: ~
        # -- Sets the write timeout duration used when writing the request to the server. The
        # default is PT60S (60 seconds). Must be a valid ISO duration. Not overridable on a
        # per-filesystem basis.
        writeTimeout: ~
        # -- Sets the maximum idle time for a connection to be kept alive. The default is PT60S (60
        # seconds). Must be a valid ISO duration. Not overridable on a per-filesystem basis.
        connectionIdleTimeout: ~
        # -- The size of each data chunk returned from the service in bytes. The default value is 4
        # MB. Not overridable on a per-filesystem basis.
        readBlockSize: ~
        # -- Sets the block size in bytes to transfer at a time. Not overridable on a per-filesystem
        # basis.
        writeBlockSize: ~

      # -- Custom ADLS configuration options, see javadocs of com.azure.core.util.Configuration.
      # Not overridable on a per-filesystem basis.
      advancedConfig: {}


# -- Advanced configuration.
# You can pass here any valid Nessie or Quarkus configuration property.
# Any property that is defined here takes precedence over all the other configuration values generated by this chart.
# Properties can be passed "flattened" or as nested YAML objects (see examples below).
advancedConfig:
  {}
# Nessie version store settings
# -----------------------------
#
#  See description of the various cache size parameters and their defaults.
#
#  nessie.version.store.persist.cache-capacity-mb: (defaults to fractional size, based on max-heap size)
#  nessie.version.store.persist.cache-capacity-fraction-of-heap: 0.7
#  nessie.version.store.persist.cache-capacity-fraction-adjust-mb: 256
#  nessie.version.store.persist.cache-capacity-fraction-min-size-mb: 64
#
#  nessie.server.default-branch: my-branch
#
#  nessie.version.store.persist.repository-id: my-repository
#
# Logging (via Quarkus)
# ---------------------
#
#  quarkus:
#    log:
#      console.format: "%d{HH:mm:ss} %s%e%n"
#      category."org.projectnessie".level: DEBUG
#
# Reverse Proxy Settings
# ----------------------
#
# These config options are mentioned only for documentation purposes. Consult the
# Quarkus documentation for "Running behind a reverse proxy" and configure those
# depending on your actual needs.
#
# See https://quarkus.io/guides/http-reference#reverse-proxy
#
# Do NOT enable these option unless your reverse proxy (for example istio or nginx)
# is properly setup to set these headers but also filter those from incoming requests.
#
#  quarkus:
#   http:
#     proxy:
#       proxy-address-forwarding: "true"
#       allow-x-forwarded: "true"
#       enable-forwarded-host: "true"
#       enable-forwarded-prefix: "true"
#       trusted-proxies: "127.0.0.1"

# -- Advanced configuration via Environment Variables.
# Extra environment variables to add to the Nessie server container.
# You can pass here any valid EnvVar object:
# https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#envvar-v1-core
# This can be useful to get configuration values from Kubernetes secrets or config maps.
extraEnv:
  []
#  - name: QUARKUS_MONGODB_APPLICATION_NAME
#    value: my-app
#  - name: QUARKUS_MONGODB_TLS
#    valueFrom:
#      configMapKeyRef:
#        name: mongodb-config
#        key: tls

authentication:
  # -- Specifies whether authentication for the nessie server should be enabled.
  enabled: false
  # -- Sets the base URL of the OpenID Connect (OIDC) server. Needs to be overridden with authentication.enabled=true.
  oidcAuthServerUrl: http://127.255.0.0:0/auth/realms/unset/
  # -- Set the OIDC client ID when authentication.enabled=true. Each application has a client ID that is used to identify the application
  # when contacting the OIDC server.
  oidcClientId: nessie
  # -- Set the OIDC client secret. Whether the client secret is required depends on the OIDC server configuration.
  # For Keycloak, the client secret is generally not required as the returned tokens can be introspected locally by Nessie.
  # If token introspection requires a round-trip to the OIDC server, the client secret is required.
  oidcClientSecret: {}
#    name: nessie-oidc-creds
#    key: client-secret

authorization:
  # -- Specifies whether authorization for the nessie server should be enabled.
  enabled: false
  # -- The authorization rules when authorization.enabled=true. Example rules can be found at https://projectnessie.org/features/metadata_authorization/#authorization-rules
  rules:
    {}
    # allowViewingBranch: op=='VIEW_REFERENCE' && role.startsWith('test_user') && ref.startsWith('allowedBranch')
    # allowCommits: op=='COMMIT_CHANGE_AGAINST_REFERENCE' && role.startsWith('test_user') && ref.startsWith('allowedBranch')

tracing:
  # -- Specifies whether tracing for the nessie server should be enabled.
  enabled: false
  # -- The collector endpoint URL to connect to (required).
  # The endpoint URL must have either the http:// or the https:// scheme.
  # The collector must talk the OpenTelemetry protocol (OTLP) and the port must be its gRPC port (by default 4317).
  # See https://quarkus.io/guides/opentelemetry for more information.
  endpoint: "http://otlp-collector:4317"
  # -- Which requests should be sampled. Valid values are: "all", "none", or a ratio between 0.0 and
  # "1.0d" (inclusive). E.g. "0.5d" means that 50% of the requests will be sampled.
  sample: "1.0d"
  # -- Resource attributes to identify the nessie service among other tracing sources.
  # See https://opentelemetry.io/docs/reference/specification/resource/semantic_conventions/#service.
  # If left empty, traces will be attached to a service named "Nessie"; to change this, provide a service.name attribute here.
  attributes:
    {}
    # service.name: my-nessie

metrics:
  # -- Specifies whether metrics for the nessie server should be enabled.
  enabled: true
  # -- Additional tags (dimensional labels) to add to the metrics.
  tags:
    {}
    # service: nessie
    # environment: production

serviceMonitor:
  # -- Specifies whether a ServiceMonitor for Prometheus operator should be created.
  enabled: true
  # -- The scrape interval; leave empty to let Prometheus decide. Must be a valid duration, e.g. 1d, 1h30m, 5m, 10s.
  interval: ""
  # -- Labels for the created ServiceMonitor so that Prometheus operator can properly pick it up.
  labels:
    {}
    # release: prometheus

serviceAccount:
  # -- Specifies whether a service account should be created.
  create: true
  # -- Annotations to add to the service account.
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template.
  name: ""

# -- Annotations to apply to nessie pods.
podAnnotations: {}

# -- Additional Labels to apply to nessie pods.
podLabels: {}

# -- Additional Labels to apply to nessie configmap.
configMapLabels: {}

# -- Security context for the nessie pod. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/.
podSecurityContext:
  {}
  # fsGroup: 2000

# -- Security context for the nessie container. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/.
securityContext:
  {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# Nessie service settings.
service:
  # -- The type of service to create.
  type: ClusterIP
  # -- The port on which the service should listen.
  port: 19120
  # -- The session affinity for the service. Valid values are: None, ClientIP.
  # ClientIP enables sticky sessions based on the client's IP address.
  # This is generally beneficial to Nessie deployments, but some testing may be
  # required in order to make sure that the load is distributed evenly among the pods.
  # Also, this setting affects only internal clients, not external ones.
  # If Ingress is enabled, it is recommended to set sessionAffinity to None.
  sessionAffinity: None
  # -- Annotations to add to the service.
  annotations: {}

# Nessie Ingress settings.
# These settings generate an Ingress resource that routes external traffic to the Nessie service.
# Consider enabling sticky sessions based on the remote client's IP address;
# this is generally beneficial to Nessie deployments, but some testing may be
# required in order to make sure that the load is distributed evenly among the pods.
# Check your ingress controller's documentation.
ingress:
  # -- Specifies the ingressClassName; leave empty if you don't want to customize it
  className: ""
  # -- Specifies whether an ingress should be created.
  enabled: false
  # -- Annotations to add to the ingress.
  annotations: {
    # nginx.ingress.kubernetes.io/upstream-hash-by: "$binary_remote_addr"
  }
  # -- A list of host paths used to configure the ingress.
  hosts:
    - host: chart-example.local
      paths: []
  # -- A list of TLS certificates; each entry has a list of hosts in the certificate,
  # along with the secret name used to terminate TLS traffic on port 443.
  tls: []
#    - hosts:
#        - chart-example1.local
#        - chart-example2.local
#      secretName: secret1

# -- Configures the resources requests and limits for nessie pods.
# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
resources:
  {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  # -- Specifies whether automatic horizontal scaling should be enabled.
  # Do not enable this when using ROCKSDB version store type.
  enabled: false
  # -- The minimum number of replicas to maintain.
  minReplicas: 1
  # -- The maximum number of replicas to maintain.
  maxReplicas: 3
  # -- Optional; set to zero or empty to disable.
  targetCPUUtilizationPercentage: 80
  # -- Optional; set to zero or empty to disable.
  targetMemoryUtilizationPercentage:

# -- Node labels which must match for the nessie pod to be scheduled on that node. See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector.
nodeSelector:
  {}
  # kubernetes.io/os: linux

# -- A list of tolerations to apply to nessie pods. See https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/.
tolerations: []
#  - key: "node-role.kubernetes.io/control-plane"
#    operator: "Exists"
#    effect: "NoSchedule"

# -- Affinity and anti-affinity for nessie pods. See https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity.
affinity: {}
#  podAffinity:
#    preferredDuringSchedulingIgnoredDuringExecution:
#      - weight: 100
#        podAffinityTerm:
#          topologyKey: kubernetes.io/hostname
#          labelSelector:
#            matchExpressions:
#              - key: app.kubernetes.io/name
#                operator: In
#                values:
#                  - nessie
